[
  {
    "id": "1b0167a4-cfdb-4445-a8b6-7ce6ba2c5fb9",
    "paper_id": 23,
    "anchor": {
      "start": 413,
      "end": 1631,
      "quote": "Recent code large language models (LLMs) have shown promising performance in generating standalone functions. However, they face limitations in repository-level code generation due to their lack of awareness of repository-level dependencies (e.g., user-defined attributes), resulting in dependency errors such as undefined-variable and no-member errors. In this work, we introduce ToolGen, an approach that integrates autocompletion tools into the code LLM generation process to address these dependencies. ToolGen comprises two main phases: Trigger Insertion and Model Fine-tuning (Offline), and Tool-integrated Code Generation (Online). During the offline phase, ToolGen augments functions within a given code corpus with a special mark token, indicating positions to trigger autocompletion tools. These augmented functions, along with their corresponding descriptions, are then used to fine-tune a selected code LLM. In the online phase, ToolGen iteratively generates functions by predicting tokens step-by-step using the fine-tuned LLM. Whenever a mark token is encountered, ToolGen invokes the autocompletion tool to suggest code completions and selects the most appropriate one through constrained greedy search."
    },
    "note": "测试1",
    "color": "#FFE58F",
    "created_at": "2025-09-01T14:16:19.842031",
    "updated_at": "2025-09-01T14:16:19.842031"
  },
  {
    "id": "1c1e6310-82b1-4e4d-9c78-4ea32a9c367c",
    "paper_id": 23,
    "anchor": {
      "start": 1934,
      "end": 2391,
      "quote": "y-based metrics: Dependency Coverage and Static Validity Rate. The results demonstrate that ToolGen significantly improves Dependency Coverage by 31.4%3 1 . 4 \\%31.4% to 39.1%3 9 . 1 \\%39.1% and Static Validity Rate by 44.9%4 4 . 9 \\%44.9% to 57.7%5 7 . 7 \\%57.7% across the three LLMs, while maintaining competitive or improved performance in widely recognized similarity metrics such as BLEU-4, CodeBLEU, Edit Similarity, and Exact Match. On the CoderEval"
    },
    "note": "测试2",
    "color": "#C7F5D9",
    "created_at": "2025-09-01T14:16:33.881406",
    "updated_at": "2025-09-01T14:16:33.881406"
  },
  {
    "id": "6af1acb9-e368-4958-be90-fa6b649b3ee9",
    "paper_id": 23,
    "anchor": {
      "start": 3594,
      "end": 4006,
      "quote": "nts have introduced a variety of code large language models (LLMs) [7, 12, 13, 15, 17, 21, 28, 29, 33, 37, 46, 53, 54] constructed upon the Transformer model architecture [45], achieving promising performance in code-related applications [19, 20, 47—50, 52, 57, 59, 60]. These models are either pre-trained or fine-tuned on extensive code corpora, enabling them to automatically generate code based on provided n"
    },
    "note": "批注X",
    "color": "#FFE58F",
    "created_at": "2025-09-01T14:17:30.197649",
    "updated_at": "2025-09-01T14:17:30.197649"
  },
  {
    "id": "7c011239-3797-429c-a087-7978719d9a1d",
    "paper_id": 23,
    "anchor": {
      "start": 2565,
      "end": 2855,
      "quote": "ss(ϖ1)) for CodeT5 and CodeLlama, respectively, while maintaining the same pass rate for CodeGPT. ToolGen also demonstrates high efficiency in repository-level code generation, with latency ranging from 0.63 to 2.34 seconds for generating each function. Furthermore, our generalizability ev"
    },
    "note": "新的批注",
    "color": "#FFE58F",
    "created_at": "2025-09-01T15:03:55.878370",
    "updated_at": "2025-09-01T15:03:55.878370"
  }
]